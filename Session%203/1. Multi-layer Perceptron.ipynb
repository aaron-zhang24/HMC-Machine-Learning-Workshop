{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPKdGJlDLCXZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-Layer Perceptron (MLP) for XOR gate\n",
    "\n",
    "The perceptron that we used for the OR and AND gates can only give us a **linear boundary**. It is evident that it is simply not possible for a linear decision boundary to correctly classify all the points in XOR gate. \n",
    "<br/>\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=1zdlTFiFPoNMSh7wuv9CjnriQpfdVDwE0\" />\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1eejQDuWSzGkdHAdYABbd_NDAT8A1zj13\" width=\"410\" /> \n",
    "<br/> <br/> <br/> <br/>\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1mDyw_mwHch-oKWac9K2NNMFvtScmWEey\" width=\"600\" /> \n",
    "\n",
    "\n",
    "It is pretty common for real-life classification problems to have non-linear decision boundaries. That is why we add hidden layers to the neural networks. The layers other than the input and output layers in the network are called hidden layers. Deep Learning typically means that the network is pretty deep (many hidden layers!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yQ17AgwLCXi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that XOR gate is equivalent to combining NAND (negative of AND) gate and OR gate with a AND gate. Can you fill in the weights for the XOR gate network. Use [jamboard here](https://jamboard.google.com/d/1yadCM1E_QF37uxcqd8Hhfz_05s1Dyc1rGdExayBQ5CM/edit?usp=sharing\n",
    ") if you'd like.\n",
    "\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=1Y_fV5rwkYUgbAmTOHRWHHv5fiQRON4Bi\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yQ17AgwLCXi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "See [solution here](https://drive.google.com/file/d/1k2enUhtaktvZ7OCdSp2o9oWqTiKN62i_/view?usp=sharing) for the XOR gate network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KByhyhbFLCXj"
   },
   "source": [
    "### Formulating Multi-Layer Perceptron (MLP) (or Fully Connected Network)\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Mohamed_Zahran6/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png\" height=\"300\" />\n",
    "\n",
    "Notations:\n",
    "* Each unit represented as a circle is called a node. \n",
    "* The first layer of the network is called the input layer. \n",
    "    * It takes input values for the examples. \n",
    "    * The number of nodes in the input layer is equal to the number of independent variables in the dataset.\n",
    "* The last layer is called the output layer. \n",
    "    * It makes the prediction. \n",
    "    * For a binary classification, there is a single node in the output layer.\n",
    "    * For multiclass (more than two) problem, the number of output nodes equals the number of classes.\n",
    "* All the intermediate layers are called hidden layers and there can be several of them.\n",
    "* For the vanilla network, every node from one layer is connected to every node in the next layer and the connections are given by weights.\n",
    "* All layers except the output layer have a bias node, though they are often not shown in the neural network diagrams.\n",
    "    * The bias always gets the input of $1$ \n",
    "    * The bias has no incoming connection from the nodes in the previous layers, unlike other nodes in the hidden layers. \n",
    "    * The bias is connected to each node in the next layer, just like other nodes.\n",
    "* The output/activation of each layer is calculated in two steps: weighted sum of the incoming input followed by the activation function (for eg. the unit step function).\n",
    "$$z_k = a_{k-1}*W_k+b_k$$\n",
    "$$a_k = g_k(z_k)$$\n",
    "* The output/activation of each hidden layer becomes the input of the next layer.\n",
    "* All the nodes in a layer share the same activation function but the activation functions can differ from layer to layer.\n",
    "* The activation functions as well as addition of hidden layers contributes to the non-linearity in the model. \n",
    "* The weights and bias of a neural network are learned using the training examples.\n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1kcWsASHFLoEgRFNpi_cxgYUElzUvOYro\" width=800 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQaaL-SDLCXk"
   },
   "source": [
    "### Probability for classification\n",
    "\n",
    "In the examples so far, the network will output either a $0$ or $1$ for negative or positive class respecively. \n",
    "\n",
    "We would usually want our classifier to give us the probabilities corresponding to each class, instead of the class label. Can you guess why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L_1ap9WLCXl"
   },
   "source": [
    "A: The examples farther from the decision boundary should be classified with more certainity (or higher probability) than those closer to the decision boundary.\n",
    "\n",
    "Our network currently outputs either $1$ or $0$ to denote the positive or negative class respectively by making use of unit step function. We want to model our network to **output $p$, the probability that an observation belongs to the positive class**. From this, we can easily compute $1-p$, the probability that an observation belongs to the negative class.\n",
    "\n",
    "What can we use instead of unit step function in the output layer to give us a probability in proportion to the distance of a point from the decision boundary?\n",
    "\n",
    "Let us first start with a math question: How do we mathematically quantify how close a point is to the decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zey7pbgBLCXm"
   },
   "source": [
    "A: The expression $x_1-x_2-1$ have values higher in magnitude for points away from the line and lower values for points closer to the line. \n",
    "\n",
    "![](https://github.com/AashitaK/ML-Workshops/blob/master/Session%204/figures/figure3.png?raw=true)\n",
    "\n",
    "The magintiude of the expression $w_1*x_1 + w_2*x_2 + \\cdots + w_n*x_n + b$ is higher for points away from the decision boundary and its sign tells us which region (positive or negative) that point fall into.\n",
    "\n",
    "If we combine the above expression with a suitable function, it can give us the probability for the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNbJ9fiZLCXn"
   },
   "source": [
    "### Sigmoid function as activation function\n",
    "\n",
    "The **sigmoid function** is defined as follows:\n",
    "$$g(t) = \\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "<img align=\"center\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/Sigmoid-function-2.svg\" width=400 />\n",
    "\n",
    "The S-shaped curve is called sigmoid because of its shape and it is widely used in population growth models and hence, the [name logistic](https://en.wikipedia.org/wiki/Logistic_function).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqgEuJ1ELCXo"
   },
   "source": [
    "Observations:\n",
    "* The output of the sigmoid lies between 0 and 1, which is the same as the range of probability. \n",
    "* It approximates to 1 for large positive values, whereas it converges to 0 for large negative values. \n",
    "* In view of the above equation for logistic regression and the properties of sigmoid logistic function, the points farther away from the line will be classified with a high probability to one class or the other, whereas the probability will be closer to 0 for points close to the line.\n",
    "\n",
    "$$p = sig(w_1*x_1 + w_2*x_2 + \\cdots + w_n*x_n + b) $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oceiBpnbLCXp"
   },
   "source": [
    "In general, we set the threshold for probability to be 0.5. This means:\n",
    "* Whenever $w_1*x_1 + w_2*x_2 + \\cdots + w_n*x_n + b$ is positive, it is classified to the positive class and the probability will be higher if the magnitude is large.\n",
    "* Whenever $w_1*x_1 + \\cdots + w_n*x_n + b < 0$ is negative, it is classified to the negative class  and the probability will be higher if the magnitude is large.\n",
    "* The points for which the value for $w_1*x_1 + \\cdots + w_n*x_n + b$ is not large in magnitude have probabilities that are closer to 0.5. Such points needs to be classified with extra care, as we will see later on in the topic of evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWT06r6rLCXq"
   },
   "source": [
    "### Formulating Loss or Cost of Classification\n",
    "\n",
    "To learn a good decision boundary, we need to make use of our training data for **finding the optimal values for the weights and biases**. We have used trial-and-error in the examples so far which clearly would not scale. Before we learn the algorithms we can use to train the network (training means learning weights and biases), we should be able to mathematically measure the \"goodness\" of a decision boundary.\n",
    "\n",
    "For the following two examples, \n",
    "* Which of the below two lines - red or green is a better decision boundary?\n",
    "* How do we decide that? What metrices should we use to guide that decision?\n",
    "* Should we only consider what percentage of points are correctly classified? If not, what else?\n",
    "\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=10gU1VISNTFjn2KFuZo_DTz_WKFNFCvn5\" width=400>\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1fCof_PfbM_VNXFf1NHE9ToObSKotrYEa\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXyVc8wyLCXr"
   },
   "source": [
    "For calculating the loss or cost of classification, we should aim for:\n",
    "* classifying the points correctly \n",
    "* maximizing the distance of correctly classified points from the decision boundary\n",
    "\n",
    "Our network outputs the probability which carries information about the distance of points from the decision boundary. We use the log loss function, also known as cross-entropy function, defined below to quantify the loss or cost function.\n",
    " \n",
    "\n",
    "Note: *There is an exponential in the definition of sigmoid function $g(t) = \\frac{1}{1+e^{-t}}$, so we will be taking the logarithm (natural or another base would not make a difference) of the output of our network. Without going into too many details, the insight for using logarithm can also be gained by the derivation of probabilities using the Maximum Likelihood Principle for a simple neural network without hidden layers. See  [here](http://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression/) and [here](https://houxianxu.github.io/2015/04/23/logistic-softmax-regression/). We will skip it because it is not relevant to the topics in this course.*\n",
    "\n",
    "\n",
    "Recall that $p$ is the probability that the data point belongs to the positive class with label $1$.  \n",
    "For points with label $y=1$, the cost is\n",
    "\n",
    "$$ c(y, p) = - \\log(p) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{ if }\\ \\  y = 1$$\n",
    "\n",
    "whereas for points with label $y=0$, the cost is\n",
    "\n",
    "$$ c(y, p) = - \\log(1-p) \\ \\  \\text{ if }\\ \\  y = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUaZTGntLCXr"
   },
   "source": [
    "Recall that:\n",
    "$$\\lim_{p \\to 1} \\log(p) = 0 \\quad \\text{ and } \\quad \\lim_{p \\to 0} \\log(p) = -\\infty$$ \n",
    "\n",
    "<img align=\"left\" src=\"https://github.com/AashitaK/ML-Workshops/blob/master/Session%204/figures/log.png?raw=true\" width=350 height=350>\n",
    "\n",
    "<img align=\"center\"  src=\"https://github.com/AashitaK/ML-Workshops/blob/master/Session%204/figures/logloss.png?raw=true\" width=350 height=350>\n",
    "<br/> <br/>\n",
    "\n",
    "Observations:  \n",
    "For data point with the true class $y=1$\n",
    "* As the predicted probability $p \\to 1$, the cost $c \\to 0$.  \n",
    "* As the predicted probability $p \\to 0$, the cost $c \\to \\infty$.\n",
    "\n",
    "For data point with the true class $y=0$\n",
    "* As the predicted probability $p \\to 0$, the cost $c \\to 0$.\n",
    "* As the predicted probability $p \\to 1$, the cost $c \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY71GcSuLCXs"
   },
   "source": [
    "The cost (also known as loss function) function takes the average over the costs for all points. The costs for the two classes $y=0$ and $y=1$ can be summed up in the following formula.\n",
    "\n",
    "$$ J = \\frac{1}{N} \\sum_{i=1}^N c(y, p) = - \\frac{1}{N} \\sum_{i=1}^N \\left(y \\log(a_2) + (1-y) \\log(1-a_2)\\right) $$\n",
    "\n",
    "where $p=Prob(y=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cG5X9kyLCXt"
   },
   "source": [
    "The cost function $J(p)$ is effectively a function of the weights and the biases $b$, that is $J(w, b)$ where $w$ and $b$ is the placeholder for all weights and biases in the network. Can you see how? \n",
    "\n",
    "Note that $x$ and $y$ are given to us and hence, are constants when it comes to training whereas the weights and the biases are the variables for which we will find the optimal values.\n",
    "\n",
    "The cost function  $J$ is something we want to minimize. How do we find the minima for a multivariate function $J$? Suppose $J$ is a function of a single variable $w$, how would you solve it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hlz5BwOLCXt"
   },
   "source": [
    "### Gradients\n",
    "\n",
    "Suppose you are standing at the top of a hill and want to descend to the plain. If you do not have any specific destination in mind, but want to take the least number of steps to reach the plain, what would be your **strategy for each step on your way**? \n",
    "\n",
    "Have you noticed the paths followed by the creeks along the mountains? \n",
    "\n",
    "Ans: You pick the direction of the steepest descent at each step.\n",
    "\n",
    "Let us formulate this optimization strategy in mathematical terms. \n",
    "\n",
    "Q: Given a curve represented by a function $J(w)$, how do you get the slope of the curve at each point?\n",
    "\n",
    "Q: Given a curve represented by a multi-variable function $J(w_1, w_2, \\dots, w_n, b)$, how do you get the slope of the curve at each point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxDfIv4eLCXu"
   },
   "source": [
    "##### What are gradients?\n",
    "Gradients can be thought of as an extension of derivatives. For a multivariable function $f$, the [gradient](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient) of $f$ is the vector of partial derivatives. \n",
    "\n",
    "$$ \\nabla f(x_1, x_2, \\dots, x_n) = \\left(\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} \\right)$$\n",
    "\n",
    "Geometrically, the gradient points in the direction of the steepest slope.\n",
    "\n",
    "**Questions to ponder over:**\n",
    "* If we move in the direction of steepest descent, are we always guaranteed to reach the minimum point?\n",
    "* If the answer is no to the above question, are there any cases for the function $J$ for which reaching the minima is guaranteed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iCDPyshLCXu"
   },
   "source": [
    "### Gradient Descent Algorithm\n",
    "Gradient Descent algorithm is used to **iteratively update the weights using the training examples so as to minimize the cost function $J$**. \n",
    "\n",
    "The weights are updated in the direction of the steepest descent of the cost function $J$ in each iteration. \n",
    "\n",
    "$$ w := w - \\alpha \\nabla J $$\n",
    "\n",
    "where $\\nabla J$ is the gradient of the cost function $J$ and $\\alpha$ is the learning rate that determines the size of steps that we take descending on the path of gradient.\n",
    "\n",
    "<img align=\"center\"  src=\"https://drive.google.com/uc?id=1K1Ki-VizvgPK88QKCQapedHItBQd8WHr\" width=\"350\" height=\"200\" />\n",
    "<p style=\"text-align: center;\"> Minimizing the cost function using gradient descent </p> \n",
    "\n",
    "In a nutshell, the learning process can be summarized as iteratively updating the weights using the training data to keep on ***minimizing the cost function***. The gist of the learning process for the neural network is the same, though the formulation of the cost function and the equation for calculating $y$ for a given $x$ will vary a lot depending on the architecture of the neural network. \n",
    "\n",
    "Let us formalize the neural networks introduced so far. There are two parts to the learning process:\n",
    "1. Forward propagation: used to predict the output by propagating the input in the forward direction\n",
    "2. Backward propagation: used to compute the weight updates for each layer by propagating the cost/error in the backward direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI58iy_1LCXy"
   },
   "source": [
    "### Forward propagation\n",
    "\n",
    "The process of propagating the output of each layer in the forward direction to consequently get the final output is called forward propagation. \n",
    "\n",
    "The output of each hidden layer becomes the input of the next layer. The output is also called the activation for a layer.\n",
    "\n",
    "The output/activation for each layer is computed in two steps:\n",
    "* The weighted sum of the inputs, say $z_i$\n",
    "* The activation function is applied to the above sum $z_i$ to produce the activation $a_i$\n",
    "  \n",
    "Equations:  \n",
    "\n",
    "$$ z^{(1)} = x \\  W^{(1)} + b^{(1)}$$\n",
    "$$ a^{(1)} = g_1(z^{(1)})$$\n",
    "$$ z^{(2)} = a^{(1)} W^{(2)}  + b^{(2)}$$\n",
    "$$ a^{(2)} = g_2(z^{(2)})$$\n",
    "$$ \\vdots $$\n",
    "$$ z^{(n)} = a^{(n-1)} W^{(n)}  + b^{(n)}$$\n",
    "$$ a^{(n)} = g_3(z^{(n)})$$\n",
    "and so on till the final output $y_{pred} = a^{(n)}$.\n",
    "\n",
    "Convention:  \n",
    "$z^{(i)}$: weighted averages of the output from the $(i-1)^{th}$ layer  \n",
    "$a^{(i)}$: activation/output of the $i^{th}$ layer  \n",
    "$g_i$: activation layer of the $i^{th}$ layer  \n",
    "$W^{(i)}$: Weight matrices connecting two layers   \n",
    "$b^{(i)}$: Bias vector for the $i$-th layer  \n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1kcWsASHFLoEgRFNpi_cxgYUElzUvOYro\" width=700 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKcwekYBLCXy"
   },
   "source": [
    "### Backward propagation\n",
    "\n",
    "The process of propagating the cost in the backward direction to compute the gradients for each layer so as to update the weights and bias is called backward propagation. \n",
    "\n",
    "Equations:    \n",
    "$$W^{(n)} := W^{(n)} - \\frac{1}{m}\\alpha \\frac{\\partial J}{\\partial W^{(n)}}$$    \n",
    "$$b^{(n)} := b^{(n)} - \\frac{1}{m}\\alpha \\frac{\\partial J}{\\partial b^{(n)}}$$\n",
    "$$ \\vdots $$\n",
    "$$ \\vdots $$ \n",
    "$$W^{(1)} := W^{(1)} - \\frac{1}{m}\\alpha \\frac{\\partial J}{\\partial W^{(1)}}$$   \n",
    "$$b^{(1)} := b^{(1)} - \\frac{1}{m}\\alpha \\frac{\\partial J}{\\partial b^{(1)}}$$  \n",
    "\n",
    "Here, $\\alpha$ is the learning rate that is multiplied to the gradients to tune the size of each weight/bias update.  \n",
    "$m$ is the number of training examples.\n",
    "\n",
    "The gradients are computed using the chain rule for derivatives.\n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1kcWsASHFLoEgRFNpi_cxgYUElzUvOYro\" width=700 />\n",
    "\n",
    "One pass of each forward and backward propagation is called an iteration. When all the training examples are iterated once, it is called an epoch.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRIrvCJ_LCX5"
   },
   "source": [
    "### Overfitting and Underfitting to the curve\n",
    "\n",
    "Three classifiers A, B and C are trained on a given labeled dataset. The accuracy of the trained classifiers in predicting the labels correctly on the same dataset is as follows.\n",
    "\n",
    "|Models | Accuracy| \n",
    "|---|---|\n",
    "| Model A | 90%|\n",
    "| Model B | 80%|\n",
    "| Model C | 70%|\n",
    "\n",
    "Clearly, model A is better at predicting labels for the training data than model B and C. Do you think model A will do a better job in predicting labels for yet unseen data as well?\n",
    "\n",
    "\n",
    "***When should we stop the iterative learning process? Until the cost function has reached its minimum value?*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "ui_XNqkqLCX5"
   },
   "source": [
    "To answer the question, let us consider this binary classification problem with two variables (features). \n",
    "\n",
    "<img align=\"center\"  src=\"https://drive.google.com/uc?id=1hsaKuZ3Pl7Msk14d-m3W1-wt9jwVNqoX\" width=\"250\" height=\"250\" />\n",
    "\n",
    "* Which of the two decision boundaries (black or green) will have a lower value for the cost function?\n",
    "* Which decision boundary would you prefer for classifying the unseen examples?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otjVwMDzLCX5"
   },
   "source": [
    "Since the cost function is calculated solely based on the training dataset, minimizing it too much might mean that the network does not generalize well to unseen examples. This is called overfitting. \n",
    "\n",
    "\n",
    "***Over-fitting and under-fitting to the training set***  \n",
    "The models can over-train on a dataset, that is they learn the dataset so well that they do not generalize well to the examples outside of that dataset. \n",
    "\n",
    "If we try to fit too complex of a curve as the decision boundary separating the classes and we don't have enough training examples to estimate the parameters for the curve, then we suffer from over-fitting.\n",
    "\n",
    "On the other hand, if we try separating the classes with an over-simplified curve as the decision boundary and we have enough training examples to estimate a curve that would be a better fit, then we suffer from under-fitting. \n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1xXgAtcmB8pJB04OaJWR8tOxSBedfziO2\" width=\"600\" height=\"300\" />\n",
    "\n",
    "How do we know whether our model is overfitting or underfitting to the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORjLbl9ULCX6"
   },
   "source": [
    "Answer: At the beginning, we save some examples as the validation set and use it to test the performance of the model. \n",
    "\n",
    "|Models | Accuracy on the training set | Accuracy on the validation set | \n",
    "|---|---|---|\n",
    "| Model A | 90%| 70% |\n",
    "| Model B | 80%| 75% |\n",
    "| Model C | 70%| 65% |\n",
    "\n",
    "* With this additional information, can you guess which model will likely perform better for the unseen data?\n",
    "* Which of these three models would you suspect for overfitting to the training data?\n",
    "* Which of these three models would you suspect for underfitting to the training data?\n",
    "\n",
    "#### Key take-aways so far:\n",
    "- Always save some examples from the datasets for testing model performance.\n",
    "- Pay attention to the model performance on the validation set rather than solely on the training set.\n",
    "- Watch out for both under-fitting and over-fitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier\n",
    "\n",
    "Logistic regression classifier is a machine learning algorithm that is often used to build a simple baseline model for binary classification tasks. It has a quick and easy implementation in `scikit-learn` package, a very useful python package in machine learning. \n",
    "\n",
    "Logistic regression is simply a neural network with no hidden layers. It is similar to perceptron except that it uses sigmoid activation function for its output instead of unit step function and thus, returns the probability for the positive class for a binary classification problem.\n",
    "\n",
    "<img align=\"center\" src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSsxeYMowCg6GcMCg2HQI3MH-ZMFWFYR16N4w&usqp=CAU\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we demonstrate how to use the built-in Logistic classifier from the `scikit-learn` module for the titanic dataset seen in the previous sessions. First, we prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Filling missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median()) \n",
    "\n",
    "# Encoding categorical variable\n",
    "df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n",
    "\n",
    "# Discarding features for simplicity\n",
    "features_to_keep = ['Age', 'Fare', 'Pclass', 'Sex']\n",
    "X = df[features_to_keep]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the dataset into training and validation sets for the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# default is 75% / 25% train-test split\n",
    "X, y = df.drop('class', axis=1), df['class']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a logistic classifier using [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the classifier using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we test the accuracy of the classifier on both training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(LR_clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on validation set: {:.2f}'\n",
    "     .format(LR_clf.score(X_valid, y_valid)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
