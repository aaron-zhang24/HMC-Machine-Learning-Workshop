{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRTknfCzuOno",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 2: Classification Algorithms \n",
    "#### Instructor: Aashita Kesarwani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0boSUGjuOnz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "**What is machine learning?**\n",
    "- Learning from data without explicit programming by using algorithms.\n",
    "\n",
    "\n",
    "Classification is one of the most basic task for machine learning algorithms yet have many widespread applications. It involves predicting classes for the data points. \n",
    "\n",
    "Data for training a classifier consists of pairs (input, output) or $(X, y)$ where $y$ is the class/label for the example $X$. For example,\n",
    "\n",
    "| Input X  | Output y |\n",
    "| ------ | ------ |\n",
    "| Emails | Classes: Spam or not |\n",
    "| Photos | Classes: cats, dogs, birds, etc. |\n",
    "| A tweet | Classes: positive or negative sentiment |\n",
    "| Medical history for patients | Classes: at risk or not for a disease |\n",
    "| Voter information | Classes: likely to cast vote for democratic or republican candidate |\n",
    "\n",
    "* Can you think of more examples that can be modeled as a classification task? \n",
    "* What about the titantic dataset where we had information about passengers and whether they survived the tragedy?\n",
    "\n",
    "**Training:**  \n",
    "In machine learning models, we use training data to build a model that can be used for future unseen data. For examples, we can use a training set of emails that are labeled to indicate whether they are spam or not and then use that model for filtering out spam emails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Classification**:\n",
    "Predicting classes for the data points.\n",
    "\n",
    "Data points are the examples in our dataset, for example each passenger in the titanic dataset that corresponded to a row in the dataframe. We always prepare our dataset so that each example is converted to a vector in $n$-dimensional space, where $n$ is the number of input variables. We will see in the later sections how to process and convert texts, images, etc. into numerical vectors.\n",
    "\n",
    "#### Decision boundary \n",
    "Decision boundary seperates the classes. We use labeled training data to determine the decision boundary and then use it to determine the labels for the unseen data.\n",
    "\n",
    "An example of the decision boundary for binary classification algorithm: \n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/f663cd4f29335972950dded4d422c07aeee8af55/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a34473067737539327250684e2d636f397076315035414032782e706e67\" width=\"400\" height=\"350\" />\n",
    "<p style=\"text-align: center;\"> Classifier separating the classes using a linear boundary  </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHACLib_uOn3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Perceptron \n",
    "The most basic neural network called [perceptron](https://en.wikipedia.org/wiki/Perceptron) was designed in 1958 to mimic a single biological neuron in our brains. When a biological neuron receives an electronic signal from its various dendrites, it fires an output signal only if the total strength of input signal passes a certain threshold. \n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=16jEisDiWZlmAYftsoekhjkU_0EhzRKih\" width=\"600\" /> \n",
    "\n",
    "where $z$ is weighted sum of inputs i.e. $ w_1 * x_1 + w_2 * x_2 + b$ and there is unit step function at the end.\n",
    "\n",
    "Mathematically, perceptron is also acting similarly:\n",
    "* It takes the weighted sum of inputs i.e. $ w_1 * x_1 + w_2 * x_2 + b$, say $z$.\n",
    "* If the weighted sum $z$ exceeds a certain threshold i.e. 0, then it outputs a $1$ (fired) or $0$ (not fired).\n",
    "\n",
    "This simple mathematical model can be used for the binary classification problem defined above using a linear decision boundary. It is not obvious how and why, so let us break down the mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7XEitL7uOn4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mathematical intuition for perceptron\n",
    "\n",
    "Let us look at the line $x_1-x_2-1=0$ in the 2D plane.\n",
    "\n",
    "![](https://github.com/AashitaK/ML-Workshops/blob/master/Session%204/figures/fig1.png?raw=true)\n",
    "\n",
    "This line looks similar to the linear decision boundary above that separated the two classes.\n",
    "\n",
    "Math question:   \n",
    "How do we mathematically represent the two regions that are separated by this line $x_1-x_2-1=0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hct2MOXuuOn4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The region containing the origin is given by $x_1-x_2-1<0$ whereas the other one by $x_1-x_2-1>0$.\n",
    "\n",
    "![](https://github.com/AashitaK/ML-Workshops/blob/master/Session%204/figures/fig2.png?raw=true)\n",
    "\n",
    "The equation for a general line can be written as\n",
    "\n",
    "$$ w_1 * x_1 + w_2 * x_2 + b = 0$$ \n",
    "\n",
    "where $w_1$, $w_2$ are determined by the slope of the line and $b$ is the intercept.\n",
    "\n",
    "The expresssions $ w_1 * x_1 + w_2 * x_2 + b < 0$ and $ w_1 * x_1 + w_2 * x_2 + b > 0$ represents the two regions divide by the plane. \n",
    "\n",
    "Let $g(x)$ be the unit step function\n",
    "$$\\begin{equation}\n",
    "g(x) = \n",
    "\\begin{cases} \n",
    "1 \\text{ if } x \\geq 0 \\\\\n",
    "0 \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}$$\n",
    "Then, we can classify the new unseen examples (texts in our case) using $g(w_1 * x_1 + w_2 * x_2 + b)$ which will output a $1$ for the positive class (spam) and a $0$ for the negative class (not-spam).\n",
    "\n",
    "Note:\n",
    "* The weight for the inputs can be negative as well, for example $w_2=-1$ in the above example. \n",
    "* The magintude of the weights is related to the significance of the corresponding input variable, provided that the variables are normalized to be in the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVqNg4zIuOn6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Q1: Can you come up with a neural network for the OR gate by trail-and-error?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=14kAMLNmAa_VRZEw6aALXQ1eFuTlse6rt\"/>\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1_PJv8NeVZbemhCBS3e8iM3hLgniDCP_o\" width=\"410\" /> \n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1mDyw_mwHch-oKWac9K2NNMFvtScmWEey\" width=\"600\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (2858810947.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/x0/1nh2smr1107g_k971xttdjnw0000gn/T/ipykernel_43948/2858810947.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    b = -1, w1 = 2, w2 = 2\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "b = -1, w1 = 2, w2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnmUX9ebuOn7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Q2: Can you come up with a neural network for the AND gate  by trail-and-error?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=1ewB3gdZZUSw3B8CxBza8EGj-ffMIAffa\" />\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1wK1pokVCcpARtJk6NQQpayEiy44Bm7mI\" width=\"410\" /> \n",
    "<br/>\n",
    "\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1mDyw_mwHch-oKWac9K2NNMFvtScmWEey\" width=\"600\" /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (2266782033.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/x0/1nh2smr1107g_k971xttdjnw0000gn/T/ipykernel_43948/2266782033.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    b = -3, w1 = 2, w2 = 2\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "b = -3, w1 = 2, w2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTPcE-mAuOn8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Q: Would a similar network work for the XOR gate?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"https://drive.google.com/uc?id=1zdlTFiFPoNMSh7wuv9CjnriQpfdVDwE0\" />\n",
    "<img align=\"center\" src=\"https://drive.google.com/uc?id=1eejQDuWSzGkdHAdYABbd_NDAT8A1zj13\" width=\"410\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z42s4UkhuOn9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Perceptron\n",
    "\n",
    "Let there be $n$ variables in our dataset, then each input must have $n$-values, i.e. $(x_1, x_2, \\dots, x_n)$. \n",
    "\n",
    "Mathematically, this means: \n",
    "* Each example is a point in the $n$-dimensional space\n",
    "* The linear decision boundary will be a $n-1$ dimensional linear hyperplane in the $n$-dimensional space.\n",
    "\n",
    "The above network can be generalized as follows.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2600/1*v88ySSMr7JLaIBjwr4chTw.jpeg\" width=\"600\" height=\"400\" />\n",
    "<p style=\"text-align: center;\"> A Perceptron Classifier</p>\n",
    "\n",
    "\n",
    "\"Training \" the perceptron so it can be used to classify new unseen examples:\n",
    "1. We start with a labeled dataset in the form of (input, label) where $(x_1, \\dots, x_n)$ values are known for each input.\n",
    "2. Solving the classification problem simply means finding the decision boundary. For a linear decision boundary, that means finding the optimal values for the weights $w_1$, $\\dots$, $w_n$, and the bias $b$.\n",
    "3. We used the trial-and-error method above that does not scale. We will be using optimization algorithms for training the neural network, which simply means finding optimal values for weights and biases. \n",
    "3. The expresssions $w_1 * x_1 + \\cdots + w_n * x_n + b < 0$ and $ w_1 * x_1 +\\cdots + w_n * x_n + b > 0$ represents the two regions divide by the hyperplane. \n",
    "4. Lastly, we classify the new unseen examples (texts in our case) using $g(w_1 * x_1 + w_2 * x_2 + b)$ where $g$ is the unit step function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "L1-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
