{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 5: Going Deeper into Neural Networks \n",
    "#### Instructor: Aashita Kesarwani\n",
    "\n",
    "\n",
    "\n",
    "##### Revision:\n",
    "* Softmax function for the output layer in multi-class classification\n",
    "* Multi-layer perceptron for regression\n",
    "* Stochastic, Batch and Mini-batch gradient descent optimizers\n",
    "* Tuning learning rate\n",
    "\n",
    "There are different choices of cost functions that are used for the neural networks. The commonly used cost functions are given below. \n",
    "\n",
    "Mean-squared Error (MSE) for regression:\n",
    "$$ J = \\frac{1}{2 n} \\sum_{i=1}^n (y^{(i)} - y_{pred}^{(i)})^2 $$\n",
    "\n",
    "Mean-absolute Error (MSE) for regression:\n",
    "$$ J = \\frac{1}{n} \\sum_{i=1}^n |y^{(i)} - y_{pred}^{(i)}| $$\n",
    "\n",
    "Log-loss/Cross-entropy for binary classification:\n",
    "$$ J = - \\frac{1}{n} \\sum_{i=1}^n y \\log(p) + (1-y) \\log(1-p)$$\n",
    "\n",
    "#### Universal approximation theorem\n",
    "\n",
    "For supervised machine learning algorithm, the goal is to best estimate the mapping function $f$ for the output variable $y$ given the input data $X$. \n",
    "\n",
    "$$ f: X \\to y$$\n",
    "\n",
    "For a classification task, the dependent variable $y$ is a class label and the $X$ consists of various independent variables encoding information that can be used to predict $y$.\n",
    "\n",
    "From the mathematical theory behind neural networks, it is known that given a function no matter how complicated, we can come up with a neural network that approximates it. See [here](http://neuralnetworksanddeeplearning.com/chap4.html) for a visual non-rigorous proof. \n",
    "\n",
    "In fact, a Multilayer Perceptron (MLP) with single hidden layer is a universal approximator, in theory. You can also look up the \"Universal Approximation Theorem\" if you're interested. \n",
    "\n",
    "Though the existence of a neural network approximating any given function is assured by mathematical theory, it is not as simple in practise to come up with suitable network parameters (parameters in this context will mean weights and biases). There are many obstacles in training a neural network to get a good approximation for the desired function. One of the most common problems we encounter, especially in deep networks, is that of vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing or Exploding Gradients\n",
    "\n",
    "Deep Learning architectures, that is neural networks with many hidden layers, are driving the recent advances in the machine learning. \n",
    "\n",
    "<img src=\"images/nn.png\" width=600>\n",
    " \n",
    "For deep neural networks, it can happen that the gradients are so small that the training process does not yield much positive results even after several epochs. The reason behind vanishing gradients lies in the backpropagation step. \n",
    "\n",
    "For a particular weight, say $w$, the weight update involves the partial derivate of the cost function, \n",
    "\n",
    "$$w := w - \\alpha \\frac{\\partial J}{\\partial w}$$\n",
    "\n",
    "Computing the gradient $\\frac{\\partial J}{\\partial W_n}$ for the weights in the very last layer $W_n$, \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_n} = \\frac{\\partial J}{\\partial y_{pred}} \\frac{\\partial y_{pred}}{\\partial W_n}$$\n",
    "\n",
    "Given the gradients for a layer, how do we compute the gradients for the preceding layer?  \n",
    "Answer: Chain rule for derivatives, again.\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_{n-1}} = \\frac{\\partial J}{\\partial W_n} \\frac{\\partial W_n}{\\partial W_{n-1}}$$\n",
    "\n",
    "When we look deeper into the calculations for the gradients, we see that it involves a series of derivatives multiplied to one another because of using the chain rule. \n",
    "Since each of these derivatives are influenced by the derivaties in the layer ahead of it, there are two possibilities:\n",
    "* Gradients vanish to zero\n",
    "$$ 0.9 * 0.8 * 0.7 * 0.6 * 0.5 * 0.4 * 0.3 * 0.2 * 0.1 \\approx 0.0004$$\n",
    "* Gradients blowing up to infinity\n",
    "$$ 1 * 2 * 3 * 4 * 5 * 6 * 7 * 8 * 9 \\approx 362880$$\n",
    "\n",
    "The earlier layers in the network are far more affected by either of these problems than the layers closer to the output because the gradients are propagated backwards adding on the multiplying factors for the earlier layers of the network.\n",
    "\n",
    "The vanishing gradients brings the process of updating weights to a standstill. Thus, running more epochs with training examples does not lead to the reduction in the cost function.\n",
    "\n",
    "\n",
    "How do we accelerate the learning process of our network?\n",
    "* Does the number of layers make a difference? \n",
    "* Does the number of nodes in each layer make a difference?\n",
    "* Does weight initialization make a difference?\n",
    "* Does the activation function make a difference?\n",
    "* Does the learning rate make a difference?\n",
    "* Does the scale of the features(variables) make a difference?\n",
    "\n",
    "Let us revisit the sigmoid function. What do you observe about the derivative (slope) of the sigmoid function at different points?\n",
    "\n",
    "$$sig(t) = \\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/Sigmoid-function-2.svg\" width=400 />\n",
    "\n",
    "The derivative of the sigmoid function becomes vanishingly small in the saturating regions on both sides. This will prevent the weights from updating their values.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3946/1*6A3A_rt4YmumHusvTvVTxw.png\" width=500 />\n",
    "\n",
    "Note that the derivative of sigmoid function is $g'(x) = g(x)\\left(1-g(x)\\right)$ and its maximum value is $0.25$ when $x=0$. This reduces the values of the gradients in the backpropagation steps and thus adds to the vanishing gradient problem.\n",
    "\n",
    "Hence, another activation function ReLU is preferred over the sigmoid activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "#### Rectified Linear Units (ReLU):\n",
    "Rectified Linear Units (ReLU) function is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "g(x) = \n",
    "\\begin{cases} \n",
    "x \\text{ if } x \\geq 0 \\\\\n",
    "0 \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2565/1*DfMRHwxY1gyyDmrIAd-gjQ.png\" width=400 />\n",
    "\n",
    "It is simply the identity function for positive values and hence, lets the weighted sum pass through it without modification but shuts down the activation when the weighted sum is negative.\n",
    "\n",
    "It's derivative \n",
    "\\begin{equation}\n",
    "g'(x) = \n",
    "\\begin{cases} \n",
    "1 \\text{ if } x \\geq 0 \\\\\n",
    "0 \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Other than addressing the vanishing gradient problem, ReLU also speeds up the training process significantly as compared to the sigmoid function and hence, it is the most commonly used activation function for the hidden layers.\n",
    "\n",
    "**Cons:** \n",
    "* Unlike the sigmoid/softmax activation functions, ReLU is not suitable for the output layer of a network designed for classification. \n",
    "* ReLU can lead to dead neurons explained below.\n",
    "* ReLU is not differentiable at $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dead neurons\n",
    "\n",
    "ReLU as well as its derivative is zero for negative values. It means that for negative weighted sum, the output of the neuron will be zero and it will also not contribute towards updating weights connecting to it in the backpropagation step (check the derivation to see where the weighted sum comes into picture). Such a neuron is irreplacably dead. This is likely to happen if the biases are initialized to large negative values. Another likely scenario for dying neurons would be if the learning rate is too high. In this case, for a positive gradient and a small positive weight, a large update can result in negative weight which can in turn lead to negative weight sum and hence, dead neuron. \n",
    "\n",
    "$$ w := w - \\alpha \\frac{\\partial J}{\\partial w} $$\n",
    "\n",
    "*He weight initialization* explained below is shown to address the problem of dead neurons. Lowering the learning rate $\\alpha$ is helpful too. A variant of ReLU called Leaky ReLU can be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaky ReLU\n",
    "\n",
    "Leaky ReLU tries to fix the dying ReLU problem by allowing a small constant slope $\\alpha$ for negative values.\n",
    "\n",
    "\\begin{equation}\n",
    "g(x) = \n",
    "\\begin{cases} \n",
    "x \\quad \\text{ if } x \\geq 0 \\\\\n",
    "\\alpha x \\quad \\text{if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is a positive constant usually $0.01$.\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/leakyrelu.png\" width=300 />\n",
    "\n",
    "It's derivative\n",
    "\\begin{equation}\n",
    "g'(x) = \n",
    "\\begin{cases} \n",
    "1 \\quad \\text{if } x \\geq 0 \\\\\n",
    "\\alpha \\quad \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/leakyrelu_prime.png\" width=300 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential Linear Unit (ELU):\n",
    "\n",
    "Exponential Linear Unit (ELU) matches ReLU for positive values as they both are identity functions. For negative values, \n",
    "\n",
    "\\begin{equation}\n",
    "g(x) = \n",
    "\\begin{cases} \n",
    "x \\quad \\quad \\quad \\quad \\text{if } x \\geq 0 \\\\\n",
    "\\alpha (1- e^x) \\quad \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is a positive constant, usually $1$.\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/elu.png\" width=300 />\n",
    "\n",
    "It's derivative\n",
    "\\begin{equation}\n",
    "g'(x) = \n",
    "\\begin{cases} \n",
    "1 \\quad \\quad \\text{if } x \\geq 0 \\\\\n",
    "\\alpha e^x \\quad \\text{ if } x < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/elu_prime.png\" width=300 />\n",
    "\n",
    "ELU does not suffer from the problem of vanishing gradients or dead neurons (since the gradient is non-zero for negative values). Though it is computationally slower than ReLU, it convergences faster so overall computationally fast. It also often results in higher accuracy. For $\\alpha=1$, it is continuous and differentiable at all points. It is very well suitable for deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization\n",
    "\n",
    "To address the vanishing gradient problems, the general rule for weight initialization is:\n",
    "* Generate a random sample from the standard normal distribution (also known as [Guassian distribution](https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/more-on-normal-distributions/v/introduction-to-the-normal-distribution))\n",
    "* Multiply each weight by $\\sqrt{\\frac{2}{n_i}}$ where $n_i$ is the number of nodes in that layer \n",
    "\n",
    "More information on this topic can be found in [this paper](http://proceedings.mlr.press/v9/glorot10a.html) by Xavier Glorot and Yoshua Bengio, who introduced this rule. [This video](https://www.coursera.org/lecture/deep-neural-network/weight-initialization-for-deep-networks-RwqYe) on coursera is also helpful.\n",
    "\n",
    "In Keras, this weight initialization rule can implemented by passing `kernel_initializer='glorot_normal'` to the `add(Dense())` function while defining the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing overfitting\n",
    "#### Regularization\n",
    "When we have weights that are higher in magnitude, the model is more likely to overfit, so we want to penalize the weights. This is achieved by adding regularization term to the error term in the cost function. \n",
    "\n",
    "There are two common ways to add the regularization term (using [$L1$ and $L2$-norms](https://machinelearningmastery.com/vector-norms-machine-learning/)) \n",
    "\n",
    "Cost function without regularization:\n",
    "$$ J = \\frac{1}{2 n} \\sum_{i=1}^n (y^{(i)} - y_{pred}^{(i)})^2 $$\n",
    "\n",
    "Cost function with L2 regularization:\n",
    "$$ J = \\frac{1}{2 n} \\sum_{i=1}^n (y^{(i)} - y_{pred}^{(i)})^2 + c \\sum_{j=1}^m w_j^2$$\n",
    "\n",
    "Cost function with L1 regularization:\n",
    "$$ J = \\frac{1}{2 n} \\sum_{i=1}^n (y^{(i)} - y_{pred}^{(i)})^2 + c \\sum_{j=1}^m |w_j|$$\n",
    "\n",
    "As the training process tries to minimize the cost function, the regularization term ensures that the weights are kept small and thereby simplifies the model.\n",
    "\n",
    "Forward propagation step remains unchanged, whereas the formulae for the backpropagation step that contains the gradients of the cost w.r.t weights changes:\n",
    "$$ w := w - \\alpha \\frac{\\partial J}{\\partial w}$$\n",
    "\n",
    "This technique of regularization using either $L1$ or $L2$-norm is one of the two most commonly used techniques to address overfitting in deep neural networks. The other one being Dropout regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "\n",
    "Drop-out means dropping out (or ignoring) some randomly chosen nodes during the training of the neural network. \n",
    "\n",
    "* For each iteration in the training, some nodes are dropped (or their activations are switched off). \n",
    "* The same nodes are dropped for both forward and backward propagation. \n",
    "* The nodes to be dropped off are chosen at random. Each node is given the probability $p$ that it will be kept and the probability $1-p$ that it will be dropped. Whether each node would be dropped or not is chosen at random with the given probabilities. This results in roughly $1-p$ proportion of nodes being dropped out in each iteration.\n",
    "* The dropout is implemented on all layers, except the output layer since it would not make much sense to drop the output nodes.\n",
    "* The dropout is implemented only during the training phase. It is not used for the predictions once the weights are trained.\n",
    "\n",
    "\n",
    "The network learns multiple independent representation and hence, it is less sensitive to specific weights, thus reducing overfitting. In some ways, a network with dropout is like having an ensemble of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features:\n",
    "\n",
    "Suppose, we have only two features $x_1$ and $x_2$. Let us also suppose that $x_1$ takes values in the range of $0$ to $0.1$ whereas $x_2$ takes values in the range of $100$ to $500$. How do you think the difference in the scales of the two features will affect the training process of the network?\n",
    "\n",
    "If the scales of the features vary a lot, the gradient descent takes a longer time to converges. It is helpful to normalize the features to be in the range of $-1$ to $1$ to speed up the learning process. \n",
    "\n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2018/01/Screen-Shot-2018-01-23-at-2.27.20-PM.png\" width=600 />\n",
    "\n",
    "If the input features are not in the typical range of $-1$ to $1$, the default parameters for the network such as learning rate can also not work properly for the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Tensorflow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=10&networkShape=4,2&seed=0.93390&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### [Worlde](https://www.nytimes.com/games/wordle/index.html)\n",
    "\n",
    "Suppose you join the  [Worlde](https://www.nytimes.com/games/wordle/index.html) team and your assigned task is to increase the difficulty level of the game by coming up with target words that are difficult to guess. Wordle team has shared with you data which contain information about the performance of all the users who played the daily game (that is for every word, how many users correctly guessed the word and those who did, how many attempts it took them). Can you make use of neural network for your task?   Explain your solution thoroughly, while making sure to include the following details:\n",
    "* Is it a classification or regression task? If classification, what are the classes? If regression, what does the output denote?\n",
    "* What would your training data look like in terms of (Input, Ouput) pairs? \n",
    "* How do you vectorize your input? It is fine to use simple solutions without any methods we learned in the class.\n",
    "* Specify the number of nodes in the input and output layer.\n",
    "* Specify the cost function.\n",
    "* How will you apply the trained network for coming up with new difficult target words to guess?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
